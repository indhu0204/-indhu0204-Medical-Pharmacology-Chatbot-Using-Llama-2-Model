{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from faiss-cpu) (1.24.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: langchain in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (0.2.16)\n",
      "Requirement already satisfied: sentence-transformers in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (3.1.1)\n",
      "Requirement already satisfied: ctransformers in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (3.10.8)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (0.2.41)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (0.1.131)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (1.24.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (4.45.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (4.66.5)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.3 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (0.25.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sentence-transformers) (10.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (2024.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from huggingface-hub>=0.19.3->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers) (0.20.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.5.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-cpu\n",
    "import numpy as np\n",
    "!pip install langchain sentence-transformers ctransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import CTransformers\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\users\\hp\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages (from pypdf) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pypdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load and split documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data_directory):\n",
    "    loader = DirectoryLoader(data_directory, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text(documents):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(documents)\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of text chunks: 4747\n"
     ]
    }
   ],
   "source": [
    "# Load and split your PDF documents\n",
    "extracted_data = load_pdf(\"data/\")\n",
    "text_chunks = split_text(extracted_data)\n",
    "print(\"Number of text chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_38488\\55377394.py:4: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
      "c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def get_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = get_embeddings()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create FAISS vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create FAISS vector store from text chunks\n",
    "docsearch = FAISS.from_texts([chunk.page_content for chunk in text_chunks], embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save FAISS index\n",
    "docsearch.save_local(\"faiss_index\")\n",
    "\n",
    "# Load FAISS index with `allow_dangerous_deserialization=True`\n",
    "docsearch = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set Up RetrievalQA with FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import CTransformers\n",
    "\n",
    "# Define your prompt template\n",
    "prompt_template = \"\"\"\n",
    "Use the following pieces of information to answer the user's question.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\n",
    "Only return the helpful answer below and nothing else.\n",
    "Helpful answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize your LLM (Ensure the model path is correct)\n",
    "llm = CTransformers(\n",
    "    model=r'C:\\Users\\HP\\OneDrive\\Documents\\GitHub\\medical-study-chatbot-using-llama2\\models\\llama-2-7b-chat.ggmlv3.q4_0.bin',  # Note the change here\n",
    "    model_type=\"llama\",\n",
    "    config={\n",
    "        'max_new_tokens': 512,\n",
    "        'temperature': 0.8\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=docsearch.as_retriever(search_kwargs={'k': 2}),\n",
    "        return_source_documents=True,\n",
    "        chain_type_kwargs=chain_type_kwargs\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Intravenous (IV) injection.\n",
      "Response: The user is asking about the type of injection used for the drug in question. Intravenous (IV) injection is the type of injection used when the drug is injected directly into a vein, typically through a needle or cannula. This method allows the drug to be delivered directly into the bloodstream, bypassing the digestive system and potentially reducing side effects.\n",
      "Exiting the chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    while True:\n",
    "        user_input = input(\"Input Prompt (type 'exit' to quit): \")\n",
    "        if user_input.lower() == \"exit\":\n",
    "            print(\"Exiting the chatbot. Goodbye!\")\n",
    "            break\n",
    "        result = qa.invoke({\"query\": user_input})  \n",
    "        print(\"Response:\", result[\"result\"])\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nChatbot interrupted. Exiting...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_38488\\3237070371.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa({\"query\": user_input})\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2357, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 864, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_38488\\3237070371.py\", line 5, in chatbot\n",
      "    result = qa({\"query\": user_input})\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 180, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 381, in __call__\n",
      "    return self.invoke(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 164, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 154, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\retrieval_qa\\base.py\", line 153, in _call\n",
      "    answer = self.combine_documents_chain.run(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 180, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 603, in run\n",
      "    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 180, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 381, in __call__\n",
      "    return self.invoke(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 164, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 154, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\combine_documents\\base.py\", line 138, in _call\n",
      "    output, extra_return_dict = self.combine_docs(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\combine_documents\\stuff.py\", line 257, in combine_docs\n",
      "    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\llm.py\", line 316, in predict\n",
      "    return self(kwargs, callbacks=callbacks)[self.output_key]\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\_api\\deprecation.py\", line 180, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 381, in __call__\n",
      "    return self.invoke(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 164, in invoke\n",
      "    raise e\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\base.py\", line 154, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\llm.py\", line 126, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain\\chains\\llm.py\", line 138, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 750, in generate_prompt\n",
      "    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 944, in generate\n",
      "    output = self._generate_helper(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 787, in _generate_helper\n",
      "    raise e\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 774, in _generate_helper\n",
      "    self._generate(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_core\\language_models\\llms.py\", line 1508, in _generate\n",
      "    self._call(prompt, stop=stop, run_manager=run_manager, **kwargs)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\langchain_community\\llms\\ctransformers.py\", line 104, in _call\n",
      "    for chunk in self.client(prompt, stop=stop, stream=True):\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\ctransformers\\llm.py\", line 432, in _stream\n",
      "    for token in self.generate(\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\ctransformers\\llm.py\", line 390, in generate\n",
      "    self.eval(tokens, batch_size=batch_size, threads=threads)\n",
      "  File \"c:\\Users\\HP\\anaconda3\\envs\\medsstudychatbot\\lib\\site-packages\\ctransformers\\llm.py\", line 307, in eval\n",
      "    status = self.ctransformers_llm_batch_eval(\n",
      "OSError: exception: integer divide by zero\n"
     ]
    }
   ],
   "source": [
    "def chatbot(user_input):\n",
    "    if user_input.lower() == \"exit\":\n",
    "        return \"Exiting the chatbot. Goodbye!\"\n",
    "    \n",
    "    result = qa({\"query\": user_input})\n",
    "    response = result[\"result\"]\n",
    "    \n",
    "\n",
    "    return response\n",
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Medical Pharmacology Chat bot\")\n",
    "    user_input = gr.Textbox(lines=2, placeholder=\"Enter your query here...\", label=\"User Input\")\n",
    "    output = gr.Textbox(lines=10, label=\"Response\")\n",
    "    \n",
    "    submit_btn = gr.Button(\"Submit\")\n",
    "    submit_btn.click(fn=chatbot, inputs=user_input, outputs=output)\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsstudychatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
